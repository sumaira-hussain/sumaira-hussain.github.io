<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Sumaira Hussain Portfolio</title>
        <!-- Favicon-->
        <link rel="icon" type="image/x-icon" href="assets/favicon.ico" />
        <!-- Custom Google font-->
        <link rel="preconnect" href="https://fonts.googleapis.com" />
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
        <link href="https://fonts.googleapis.com/css2?family=Plus+Jakarta+Sans:wght@100;200;300;400;500;600;700;800;900&amp;display=swap" rel="stylesheet" />
        <!-- Bootstrap icons-->
        <link href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.8.1/font/bootstrap-icons.css" rel="stylesheet" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css">
    </head>
    <body class="d-flex flex-column h-100 bg-light">
        <main class="flex-shrink-0">
            <!-- Navigation-->
            <nav class="navbar navbar-expand-lg navbar-light bg-white py-3">
                <div class="container px-5">
                    <a class="navbar-brand" href="index.html"><span class="fw-bolder text-primary">Dr. Sumaira Hussain</span></a>
                    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
                    <div class="collapse navbar-collapse" id="navbarSupportedContent">
                        <ul class="navbar-nav ms-auto mb-2 mb-lg-0 small fw-bolder">
                           <li class="nav-item"><a class="nav-link" href="index.html">Home</a></li>
                            <li class="nav-item"><a class="nav-link" href="resume.html">Professional Milestones</a></li>
                            <li class="nav-item"><a class="nav-link" href="projects.html">Publications</a></li>
                            <li class="nav-item"><a class="nav-link" href="skill.html">Skills & Interests</a></li>
                            <li class="nav-item"><a class="nav-link" href="contact2.html">Contact</a></li>
                        </ul>
                    </div>
                </div>
            </nav>
            <!-- Projects Section-->
            <section class="py-5">
                <div class="container px-5 mb-5">
                    <div class="text-center mb-5">
                        <h1 class="display-5 fw-bolder mb-0"><span class="text-gradient d-inline">Publications</span></h1>
                        <p class="lead fw-normal text-muted mb-0">My Academic and Research Contributions</p>
                    </div>
                    <div class="row gx-5 justify-content-center">
                        <div class="col-lg-11 col-xl-9 col-xxl-8">
                            <!-- Project Card 13-->
                            <div class="card overflow-hidden shadow rounded-4 border-0 mb-5">
                                <div class="card-body p-0">
                                    <div class="d-flex align-items-center">
                                        <div class="p-5">
                                            <a class="text-primary fw-bolder mb-2" href="https://doi.org/10.1016/j.jksuci.2023.101838" ><i>CMGNet: Context-aware middle-layer guidance network for salient object detection </i> </a>
                                            <p class="small fw-bolder">Published in Journal of King Saud University - Computer and Information Sciences, 2023</p>
                                            <p class="small text-muted" ><b> Recommended citation: </b> Ullah, I., Hussain, S., Shaheed, K.,  Ali, W., Khan, S.A., Yin, Y. & Ma, Y. (2023). CMGNet: Context-aware middle-layer guidance network for salient object detection. Journal of King Saud University - Computer and Information Sciences, 101838.</p>
                                        </div>
                                        <img class="img-fluid" src="assets/CMGnet.jpg" alt="..." width="300" height="400"/>
                                    </div>
                                </div>
                            </div>

                            <!-- Project Card 12-->
                            <div class="card overflow-hidden shadow rounded-4 border-0 mb-5">
                                <div class="card-body p-0">
                                    <div class="d-flex align-items-center">
                                        <div class="p-5">
                                            <a class="text-primary fw-bolder mb-2" href="https://link.springer.com/article/10.1007/s11432-021-3340-y" ><i>Difficulty aware prior-guided Hierarchical Network for Adaptive Segmentation of Breast Tumor </i> </a>
                                            <p class="small fw-bolder">Published in SCIENCE CHINA Information Sciences, 2023</p>
                                            <p class="small text-muted" ><b> Recommended citation: </b> Hussain, S., Xi, X., Ullah, I., Naim, S. W., Shaheed, K., Tian, C., & Yin, Y. (2023). Difficulty-aware prior-guided hierarchical network for adaptive segmentation of breast tumors. Science China Information Sciences, 66(2), 122104.</p>
                                        </div>
                                        <img class="img-fluid" src="assets/DHN.png" alt="..." width="300" height="400"/>
                                    </div>
                                </div>
                            </div>
                            <!-- Project Card 11-->
                            <div class="card overflow-hidden shadow rounded-4 border-0 mb-5">
                                <div class="card-body p-0">
                                    <div class="d-flex align-items-center">
                                        <div class="p-5">
                                           <a class="text-primary fw-bolder mb-2" href="https://www.mdpi.com/1424-8220/22/24/9667" ><i>AWANet: Attentive-Aware Wide-Kernels Asymmetrical Network with Blended Contour Information for Salient Object Detection </i> </a>
                                            <p class="small fw-bolder">Published in Sensors, 2022</p>
                                            <p class="small text-muted"><b>Recommended citation: </b> Ullah, I., Jian, M., Shaheed, K., Hussain, S., Ma, Y., Xu, L., & Muhammad, K. (2022). AWANet: Attentive-Aware Wide-Kernels Asymmetrical Network with Blended Contour Information for Salient Object Detection. Sensors, 22(24), 9667.</p>
                                        </div>
                                        <img class="img-fluid" src="assets/AWA.png" alt="..." width="300" height="400"/>
                                    </div>
                                </div>
                            </div>
                            <!-- Project Card 10-->
                            <div class="card overflow-hidden shadow rounded-4 border-0 mb-5">
                                <div class="card-body p-0">
                                    <div class="d-flex align-items-center">
                                        <div class="p-5">
                                            <a class="text-primary fw-bolder mb-2" href="https://www.sciencedirect.com/science/article/abs/pii/S0010482522007193" ><i>A Discriminative Level Set Method with Deep Supervision for Breast Tumor Segmentation </i> </a>
                                            <p class="small fw-bolder">Published in Computers in Biology and Medicine, 2022</p>
                                            <p class="small text-muted" ><b> Recommended citation: </b> Hussain, S., Xi, X., Ullah, I., Inam, S. A., Naz, F., Shaheed, K., ... & Tian, C. (2022). A discriminative level set method with deep supervision for breast tumor segmentation. Computers in Biology and Medicine, 149, 105995.</p>
                                        </div>
                                        <img class="img-fluid" src="assets/DLS.png" alt="..." width="300" height="400"/>
                                    </div>
                                </div>
                            </div>
                            <!-- Project Card 9-->
                            <div class="card overflow-hidden shadow rounded-4 border-0 mb-5">
                                <div class="card-body p-0">
                                    <div class="d-flex align-items-center">
                                        <div class="p-5">
                                           <a class="text-primary fw-bolder mb-2" href="https://www.sciencedirect.com/science/article/abs/pii/S0957417421015943" ><i>DS-CNN: A Pre-trained Xception Model based on Depth-wise Separable Convolutional Neural Network for Finger Vein Recognition </i> </a>
                                            <p class="small fw-bolder">Published in Expert Systems with Applications, 2022</p>
                                            <p class="small text-muted"><b>Recommended citation: </b> Shaheed, K., Mao, A., Qureshi, I., Kumar, M., Hussain, S., Ullah, I., & Zhang, X. (2022). DS-CNN: A pre-trained Xception model based on depth-wise separable convolutional neural network for finger vein recognition. Expert Systems with Applications, 191, 116288.</p>
                                        </div>
                                        <img class="img-fluid" src="assets/DSCNN.jpg" alt="..." width="300" height="400"/>
                                    </div>
                                </div>
                            </div>
                            <!-- Project Card 8-->
                            <div class="card overflow-hidden shadow rounded-4 border-0 mb-5">
                                <div class="card-body p-0">
                                    <div class="d-flex align-items-center">
                                        <div class="p-5">
                                           <a class="text-primary fw-bolder mb-2" href="https://journals.sagepub.com/doi/full/10.1177/15501477211066305" ><i>Re-ranking vehicle re-identification with orientation-guide query expansion</i> </a>
                                            <p class="small fw-bolder">Published in International Journal of Distributed Sensor Networks, 2022</p>
                                            <p class="small text-muted"><b>Recommended citation: </b> Zhang, X., Nie, X., Sun, Z., Li, X., Wang, C., Tao, P., & Hussain, S. (2022). Re-ranking vehicle re-identification with orientation-guide query expansion. International Journal of Distributed Sensor Networks, 18(3), 15501477211066305.</p>
                                        </div>
                                        <img class="img-fluid" src="assets/OGQE.jpeg" alt="..." width="300" height="400"/>
                                    </div>
                                </div>
                            </div>
                            <!-- Project Card 7-->
                            <div class="card overflow-hidden shadow rounded-4 border-0 mb-5">
                                <div class="card-body p-0">
                                    <div class="d-flex align-items-center">
                                        <div class="p-5">
                                           <a class="text-primary fw-bolder mb-2" href="https://www.sciencedirect.com/science/article/abs/pii/S1566253521002025" ><i>Recent advancements in finger vein recognition technology: Methodology, challenges and opportunities</i> </a>
                                            <p class="small fw-bolder">Published in Information Fusion, 2022</p>
                                            <p class="small text-muted"><b>Recommended citation: </b> Shaheed, K., Mao, A., Qureshi, I., Kumar, M., Hussain, S., & Zhang, X. (2022). Recent advancements in finger vein recognition technology: methodology, challenges and opportunities. Information Fusion, 79, 84-109.</p>
                                        </div>
                                        <img class="img-fluid" src="assets/FVRT.jpg" alt="..." width="300" height="400"/>
                                    </div>
                                </div>
                            </div>
                            <!-- Project Card 6-->
                            <div class="card overflow-hidden shadow rounded-4 border-0 mb-5">
                                <div class="card-body p-0">
                                    <div class="d-flex align-items-center">
                                        <div class="p-5">
                                           <a class="text-primary fw-bolder mb-2" href="https://www.sciencedirect.com/science/article/abs/pii/S0925231221007128" ><i>Global context-aware multi-scale features aggregative network for salient object detection</i> </a>
                                            <p class="small fw-bolder">Published in Neurocomputing, 2021</p>
                                            <p class="small text-muted"><b>Recommended citation: </b> Ullah, I., Jian, M., Hussain, S., Lian, L., Ali, Z., Qureshi, I., ... & Yin, Y. (2021). Global context-aware multi-scale features aggregative network for salient object detection. Neurocomputing, 455, 139-153.</p>
                                        </div>
                                        <img class="img-fluid" src="assets/GCMA.jpg" alt="..." width="300" height="400"/>
                                    </div>
                                </div>
                            </div>
                            <!-- Project Card 5-->
                            <div class="card overflow-hidden shadow rounded-4 border-0 mb-5">
                                <div class="card-body p-0">
                                    <div class="d-flex align-items-center">
                                        <div class="p-5">
                                           <a class="text-primary fw-bolder mb-2" href="https://link.springer.com/article/10.1007/s11042-020-10111-4" ><i>DSFMA: deeply supervised fully convolutional neural networks based on multi-level aggregation for saliency detectionction</i> </a>
                                            <p class="small fw-bolder">Published in Multimedia Tools and Applications, 2021</p>
                                            <p class="small text-muted"><b>Recommended citation: </b> Ullah, I., Jian, M., Hussain, S., Guo, J., Lian, L., Yu, H., ... & Yin, Y. (2021). DSFMA: deeply supervised fully convolutional neural networks based on multi-level aggregation for saliency detection. Multimedia Tools and Applications, 80, 7145-7165.</p>
                                        </div>
                                        <img class="img-fluid" src="assets/DSFMA.jpg" alt="..." width="300" height="400"/>
                                    </div>
                                </div>
                            </div>
                            <!-- Project Card 4-->
                            <div class="card overflow-hidden shadow rounded-4 border-0 mb-5">
                                <div class="card-body p-0">
                                    <div class="d-flex align-items-center">
                                        <div class="p-5">
                                           <a class="text-primary fw-bolder mb-2" href="https://link.springer.com/article/10.1007/s11042-020-08849-y" ><i>A brief survey of visual saliency detection</i> </a>
                                            <p class="small fw-bolder">Published in Multimedia Tools and Applications, 2020</p>
                                            <p class="small text-muted"><b>Recommended citation: </b> Ullah, I., Jian, M., Hussain, S., Guo, J., Yu, H., Wang, X., & Yin, Y. (2020). A brief survey of visual saliency detection. Multimedia Tools and Applications, 79, 34605-34645.</p>
                                        </div>
                                        <img class="img-fluid" src="assets/saliency.jpg" alt="..." width="300" height="400"/>
                                    </div>
                                </div>
                            </div>
                            <!-- Project Card 3-->
                            <div class="card overflow-hidden shadow rounded-4 border-0 mb-5">
                                <div class="card-body p-0">
                                    <div class="d-flex align-items-center">
                                        <div class="p-5">
                                           <a class="text-primary fw-bolder mb-2" href="https://ieeexplore.ieee.org/abstract/document/9217481" ><i>Contextual Level-Set Method for Breast Tumor Segmentation</i> </a>
                                            <p class="small fw-bolder">Published in IEEE Access, 2020</p>
                                            <p class="small text-muted"><b>Recommended citation: </b> Hussain, S., Xi, X., Ullah, I., Wu, Y., Ren, C., Lianzheng, Z., ... & Yin, Y. (2020). Contextual level-set method for breast tumor segmentation. IEEE Access, 8, 189343-189353.</p>
                                        </div>
                                        <img class="img-fluid" src="assets/CLS.png" alt="..." width="300" height="400"/>
                                    </div>
                                </div>
                            </div>
                            <!-- Project Card 2-->
                            <div class="card overflow-hidden shadow rounded-4 border-0 mb-5">
                                <div class="card-body p-0">
                                    <div class="d-flex align-items-center">
                                        <div class="p-5">
                                           <a class="text-primary fw-bolder mb-2" href="http://paper.ijcsns.org/07_book/201906/20190617.pdf" ><i>How to address Impediments in Scrum?</i> </a>
                                            <p class="small fw-bolder">Published in International Journal of Computer Science and Network Security, 2019</p>
                                            <p class="small text-muted"><b>Recommended citation: </b> Naim, W., Hussain, S., Hassan, B., Ali, S. A., & Bhatti, P. (2019). How to address Impediments in Scrum?. IJCSNS, 19(6), 130.</p>
                                        </div>
                                        <!--<img class="img-fluid" src="assets/CLS.png" alt="..." width="300" height="400"/>-->
                                    </div>
                                </div>
                            </div>
                            <!-- Project Card 1-->
                            <div class="card overflow-hidden shadow rounded-4 border-0 mb-5">
                                <div class="card-body p-0">
                                    <div class="d-flex align-items-center">
                                        <div class="p-5">
                                           <a class="text-primary fw-bolder mb-2" href="http://paper.ijcsns.org/07_book/201905/20190517.pdf" ><i>A collaborative Model to reduce Gap between IT Industry and academia (CMRGIA)</i> </a>
                                            <p class="small fw-bolder">Published in International Journal of ComputerScience and Network Security, 2019</p>
                                            <p class="small text-muted"><b>Recommended citation: </b> Naim, S. W., Ali, S. A., Hussain, S., & Qureshi, B. H. (2019). A collaborative model to reduce gap between it industry and academia (cmrgia). International Journal of Computer Network and Information Security, 19, 118-122.</p>
                                        </div>
                                        <!--<img class="img-fluid" src="assets/CLS.png" alt="..." width="300" height="400"/>-->
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </section>
            <!-- Call to action section-->
            <section class="py-5 bg-gradient-primary-to-secondary text-white">
                <div class="container px-5 my-5">
                    <div class="text-center">
                        <h2 class="display-4 fw-bolder mb-4">Let's build something together</h2>
                        <a class="btn btn-outline-light btn-lg px-5 py-3 fs-6 fw-bolder" href="contact2.html">Contact me</a>
                    </div>
                </div>
            </section>
        </main>
        <!-- Footer-->
        <footer class="bg-white py-4 mt-auto">
            <div class="container px-5">
                <div class="row align-items-center justify-content-between flex-column flex-sm-row">
                    <div class="col-auto"><div class="small m-0">Copyright &copy; Dr. Sumaira Website 2023</div></div>
                    <div class="col-auto">
                        <a class="small" href="https://www.facebook.com/chashmanK"><i class="fab fa-facebook"></i></a>
                        <span class="mx-1">&middot;</span>
                        <a class="small" href="https://twitter.com/ChashmanK"><i class="fab fa-twitter"></i></a>
                        <span class="mx-1">&middot;</span>
                        <a class="small" href="mailto:hussain-s@outlook.com"><i class="fas fa-envelope" ></i></a>
                    </div>
                </div>
            </div>
        </footer>
        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>
